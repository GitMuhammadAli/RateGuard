# RateGuard - Complete Project Documentation

## Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture & Design Decisions](#architecture--design-decisions)
3. [Technology Stack Analysis](#technology-stack-analysis)
4. [Deployment Options](#deployment-options)
5. [Interview Defense Guide](#interview-defense-guide)

---

## Project Overview

### What is RateGuard?

**RateGuard** is an **Enterprise API Rate Limiting & Cost Management Platform** - a smart proxy that sits between your applications and external APIs (OpenAI, Stripe, Anthropic, etc.).

### The Business Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WITHOUT RateGuard                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Your App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º OpenAI API        â”‚
â”‚                                                              â”‚
â”‚  Problems:                                                   â”‚
â”‚  âœ— No control over request rates (can hit API limits)      â”‚
â”‚  âœ— Unexpected $10,000+ bills (no budget control)           â”‚
â”‚  âœ— Hard to track which team/feature uses what              â”‚
â”‚  âœ— No early warning before limits/budgets hit              â”‚
â”‚  âœ— No visibility into API performance/errors               â”‚
â”‚  âœ— Can't attribute costs to specific projects              â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WITH RateGuard                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Your App â”€â”€â–º RateGuard Proxy â”€â”€â–º OpenAI API                â”‚
â”‚                    â”‚                                         â”‚
â”‚                    â”œâ”€â”€ âœ“ Rate Limiting (100 req/min)        â”‚
â”‚                    â”œâ”€â”€ âœ“ Cost Tracking ($45.23 today)       â”‚
â”‚                    â”œâ”€â”€ âœ“ Budget Alerts (80% warning)        â”‚
â”‚                    â”œâ”€â”€ âœ“ Analytics Dashboard                â”‚
â”‚                    â”œâ”€â”€ âœ“ Per-team/key attribution           â”‚
â”‚                    â””â”€â”€ âœ“ Real-time monitoring               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features

| Feature                 | Description                                               | Business Value                      |
| ----------------------- | --------------------------------------------------------- | ----------------------------------- |
| **Rate Limiting**       | Control request rates with Token Bucket or Sliding Window | Prevent API bans, ensure fair usage |
| **Cost Tracking**       | Track spending per API, per key, per endpoint             | Budget control, cost attribution    |
| **Budget Alerts**       | Email/Slack notifications when approaching limits         | Prevent bill shock                  |
| **Multi-tenant**        | Workspaces with team members and role-based access        | Enterprise-ready                    |
| **API Key Management**  | Secure key generation, rotation, and revocation           | Security compliance                 |
| **Real-time Analytics** | Charts, logs, and performance metrics                     | Operational visibility              |

### Target Users

1. **Startups** using AI APIs (OpenAI, Anthropic) who want to control costs
2. **Enterprises** needing to manage API access across teams
3. **Platform Companies** providing API access to customers
4. **DevOps Teams** wanting visibility into API dependencies

---

## Architecture & Design Decisions

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RATEGUARD ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚  Client App â”‚  (Your application)                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚         â”‚ Authorization: Bearer rg_xxx                             â”‚
â”‚         â–¼                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚         PROXY SERVER (Fastify)          â”‚ â† Port 3001           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
â”‚  â”‚  â”‚   Auth    â”‚â†’ â”‚  Rate    â”‚â†’ â”‚Budgetâ”‚ â”‚                       â”‚
â”‚  â”‚  â”‚ Middlewareâ”‚  â”‚  Limit   â”‚  â”‚Check â”‚ â”‚                       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
â”‚  â”‚        â”‚              â”‚           â”‚     â”‚                       â”‚
â”‚  â”‚        â–¼              â–¼           â–¼     â”‚                       â”‚
â”‚  â”‚   PostgreSQL       Redis      Redis     â”‚                       â”‚
â”‚  â”‚   (API keys)    (rate state) (budget)   â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                                                           â”‚
â”‚         â–¼ If allowed                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚  Upstream   â”‚  (OpenAI, Stripe, Anthropic)                      â”‚
â”‚  â”‚    API      â”‚                                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚         â”‚ Response                                                  â”‚
â”‚         â–¼                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚       EVENT LOGGING (async)             â”‚                       â”‚
â”‚  â”‚  Proxy â†’ Kafka â†’ Analytics â†’ ClickHouse â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                                                           â”‚
â”‚         â–¼                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚      WEB DASHBOARD (Next.js)            â”‚ â† Port 3000           â”‚
â”‚  â”‚  â€¢ Real-time charts                     â”‚                       â”‚
â”‚  â”‚  â€¢ API/Key management                   â”‚                       â”‚
â”‚  â”‚  â€¢ Cost tracking                        â”‚                       â”‚
â”‚  â”‚  â€¢ Alert configuration                  â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Monorepo Structure

```
rateguard/
â”œâ”€â”€ ðŸ“± apps/                    â† Running Applications
â”‚   â”œâ”€â”€ web/                    â† Dashboard (Next.js) - User Interface
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ app/            â† Next.js App Router pages
â”‚   â”‚       â”œâ”€â”€ components/     â† React components
â”‚   â”‚       â”œâ”€â”€ hooks/          â† Custom React hooks
â”‚   â”‚       â””â”€â”€ lib/            â† Utilities, API client
â”‚   â”‚
â”‚   â”œâ”€â”€ proxy/                  â† API Proxy (Fastify) - Core Engine
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ middleware/     â† Auth, rate-limit, budget
â”‚   â”‚       â”œâ”€â”€ routes/         â† Health, proxy handlers
â”‚   â”‚       â”œâ”€â”€ services/       â† Business logic
â”‚   â”‚       â””â”€â”€ plugins/        â† Fastify plugins (Redis, Prisma)
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/              â† Event Processor - Data Pipeline
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ consumer.ts     â† Kafka consumer
â”‚   â”‚       â””â”€â”€ processor.ts    â† Event transformation
â”‚   â”‚
â”‚   â””â”€â”€ alerts/                 â† Alert Service - Monitoring
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ evaluator.ts    â† Check alert conditions
â”‚           â””â”€â”€ notifier.ts     â† Send notifications
â”‚
â”œâ”€â”€ ðŸ“¦ packages/                â† Shared Libraries (DRY principle)
â”‚   â”œâ”€â”€ db/                     â† Database (Prisma ORM)
â”‚   â”‚   â”œâ”€â”€ prisma/
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.prisma   â† Database schema
â”‚   â”‚   â”‚   â””â”€â”€ seed.ts         â† Seed data
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â””â”€â”€ index.ts        â† Prisma client export
â”‚   â”‚
â”‚   â”œâ”€â”€ rate-limiter/           â† Rate Limit Algorithms
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ algorithms/     â† Token bucket, sliding window
â”‚   â”‚       â””â”€â”€ lua/            â† Redis Lua scripts
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/              â† ClickHouse Client
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ client.ts       â† ClickHouse connection
â”‚   â”‚       â””â”€â”€ queries.ts      â† Analytics queries
â”‚   â”‚
â”‚   â””â”€â”€ shared/                 â† Types, Utils, Constants
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ types/          â† TypeScript interfaces
â”‚           â”œâ”€â”€ schemas/        â† Zod validation schemas
â”‚           â””â”€â”€ utils/          â† Crypto, validation helpers
â”‚
â”œâ”€â”€ ðŸ³ docker/                  â† Infrastructure (Development)
â”‚   â”œâ”€â”€ docker-compose.yml      â† Development services
â”‚   â””â”€â”€ clickhouse/
â”‚       â””â”€â”€ init.sql            â† ClickHouse schema
â”‚
â”œâ”€â”€ â˜¸ï¸ k8s/                      â† Infrastructure (Production)
â”‚   â”œâ”€â”€ namespace.yaml          â† Kubernetes namespace
â”‚   â”œâ”€â”€ configmaps/             â† Environment configuration
â”‚   â”œâ”€â”€ secrets/                â† Credentials (use External Secrets in prod)
â”‚   â”œâ”€â”€ databases/              â† StatefulSets (PostgreSQL, Redis, etc.)
â”‚   â”œâ”€â”€ deployments/            â† Application deployments
â”‚   â”œâ”€â”€ services/               â† Kubernetes services
â”‚   â”œâ”€â”€ ingress/                â† External access (NGINX Ingress)
â”‚   â””â”€â”€ hpa/                    â† Horizontal Pod Autoscaler
â”‚
â”œâ”€â”€ ðŸ“œ scripts/                 â† Automation
â”‚   â”œâ”€â”€ dev.sh                  â† Start development
â”‚   â””â”€â”€ setup.sh                â† Initial setup
â”‚
â””â”€â”€ pnpm-workspace.yaml         â† Monorepo configuration
```

### Why Monorepo?

**Decision: Monorepo with pnpm workspaces**

| Alternative                   | Pros                                             | Cons                                     | Why Not                                      |
| ----------------------------- | ------------------------------------------------ | ---------------------------------------- | -------------------------------------------- |
| **Polyrepo** (separate repos) | Independent deployments, clear ownership         | Code duplication, version sync nightmare | Too much overhead for small team             |
| **Monolith** (single app)     | Simple, easy to deploy                           | Can't scale components independently     | Proxy needs different scaling than dashboard |
| **Monorepo** âœ“                | Shared code, atomic commits, coordinated changes | Needs tooling                            | Best balance for our use case                |

**Defense Argument:**

> "We chose a monorepo because RateGuard has tightly coupled components that share types, utilities, and database access. A polyrepo would force us to publish internal packages to npm and manage version compatibility. With a monorepo, when we change the database schema, we can update all consumers in a single commit, run tests, and deploy atomically. Companies like Google, Meta, and Microsoft use monorepos for exactly this reason."

### Request Flow (Critical Path)

```
1. Client Request
   POST /proxy/openai/chat/completions
   Headers: Authorization: Bearer rg_live_xxxxx

2. Auth Middleware
   â”œâ”€â”€ Extract API key from header
   â”œâ”€â”€ Hash key with SHA-256
   â”œâ”€â”€ Lookup in PostgreSQL: SELECT * FROM api_keys WHERE key_hash = ?
   â”œâ”€â”€ Validate: isActive, expiresAt
   â””â”€â”€ Attach apiKey + workspace to request

3. Rate Limit Middleware
   â”œâ”€â”€ Load rules: SELECT * FROM rate_limit_rules WHERE workspace_id = ?
   â”œâ”€â”€ Find matching rules (by API, endpoint pattern)
   â”œâ”€â”€ For each rule:
   â”‚   â”œâ”€â”€ Build Redis key: rl:tb:{workspace}:{api}:{key}
   â”‚   â”œâ”€â”€ Execute Lua script (atomic check + decrement)
   â”‚   â””â”€â”€ If denied: throw 429 with Retry-After
   â””â”€â”€ Add rate limit headers to response

4. Budget Middleware
   â”œâ”€â”€ Get current spend: REDIS GET budget:{workspace}:{YYYYMM}
   â”œâ”€â”€ Estimate request cost
   â”œâ”€â”€ If spend + estimate > budget && autoShutoff:
   â”‚   â””â”€â”€ throw 402 Payment Required
   â””â”€â”€ Add budget headers to response

5. Upstream Forward
   â”œâ”€â”€ Load API config (cached in Redis)
   â”œâ”€â”€ Build upstream URL: baseUrl + path
   â”œâ”€â”€ Add authentication (Bearer, API-Key, Basic)
   â”œâ”€â”€ Forward with undici (connection pooling)
   â””â”€â”€ Measure latency

6. Response Processing
   â”œâ”€â”€ Extract token usage from response body
   â”œâ”€â”€ Calculate cost: (prompt_tokens * input_rate) + (completion_tokens * output_rate)
   â”œâ”€â”€ Update budget: REDIS INCRBY budget:{workspace}:{YYYYMM} {cost}
   â””â”€â”€ Add cost header: X-RateGuard-Cost-Cents

7. Event Logging (async, non-blocking)
   â”œâ”€â”€ Build RequestEvent object
   â”œâ”€â”€ Buffer in memory (batch of 100 or 100ms timeout)
   â””â”€â”€ Send to Kafka topic: api-events

8. Return Response
   â””â”€â”€ Proxy upstream response with added headers:
       X-RateGuard-Request-Id
       X-RateLimit-Limit, Remaining, Reset
       X-RateGuard-Cost-Cents
       X-RateGuard-Latency-Ms
```

---

## Technology Stack Analysis

### Database Layer

| Database             | Purpose                                   | Why This Choice                                  | Alternatives Considered                         |
| -------------------- | ----------------------------------------- | ------------------------------------------------ | ----------------------------------------------- |
| **PostgreSQL**       | Primary data (users, APIs, keys, configs) | ACID, JSON support, mature, excellent tooling    | MySQL (fewer features), MongoDB (no ACID)       |
| **Redis**            | Rate limiting, caching, budget counters   | In-memory speed, Lua scripting, TTL              | Memcached (no Lua), DynamoDB (expensive)        |
| **ClickHouse**       | Analytics (billions of events)            | Column-oriented, 10-100x faster for aggregations | TimescaleDB (slower), BigQuery (vendor lock-in) |
| **Kafka (Redpanda)** | Event streaming                           | Decoupling, durability, replay capability        | RabbitMQ (no replay), SQS (vendor lock-in)      |

**Defense: Why 4 databases?**

> "Each database is optimized for its specific workload. PostgreSQL handles transactional data where consistency matters (user accounts, API keys). Redis provides sub-millisecond rate limit checks - using PostgreSQL would add 10-50ms latency per request. ClickHouse handles analytics queries over billions of events that would crash PostgreSQL. Kafka provides durability and decoupling - if analytics goes down, events are safely queued. This is exactly the pattern used by Uber, Airbnb, and Stripe."

**Counter-argument: "Isn't that operationally complex?"**

> "Yes, more databases = more operational overhead. But the alternative is worse: using PostgreSQL for rate limiting would limit us to ~1000 req/sec instead of 100,000+. In production, we'd use managed services (RDS, ElastiCache, Confluent) which handle ops for us. The complexity is justified by the 100x performance improvement."

### Backend Framework

| Choice               | Why                                                        | Alternatives                                                         |
| -------------------- | ---------------------------------------------------------- | -------------------------------------------------------------------- |
| **Fastify** (Proxy)  | 2x faster than Express, built-in validation, plugin system | Express (slower), Koa (fewer features), Hono (newer, less ecosystem) |
| **Next.js 14** (Web) | Full-stack React, API routes, SSR, excellent DX            | Remix (similar), SvelteKit (smaller ecosystem)                       |
| **TypeScript**       | Type safety, refactoring, documentation                    | JavaScript (no types), Go (different ecosystem)                      |

**Defense: Why Fastify over Express?**

> "Express is request/response middleware with no opinions. Fastify is built for performance and developer experience. Key differences:
>
> 1. **Performance**: Fastify handles 30k req/s vs Express's 15k req/s in benchmarks
> 2. **Validation**: Built-in JSON Schema validation, generates types automatically
> 3. **Plugins**: Encapsulated plugins with proper dependency injection
> 4. **Async**: Native async/await without callback hell
>
> For a high-throughput proxy handling thousands of requests per second, that 2x performance matters."

### ORM Choice

| Choice     | Why                                     | Alternatives                                            |
| ---------- | --------------------------------------- | ------------------------------------------------------- |
| **Prisma** | Type-safe queries, migrations, great DX | TypeORM (more complex), Drizzle (newer), Knex (raw SQL) |

**Defense: Why Prisma over raw SQL?**

```typescript
// Raw SQL - No type safety
const user = await db.query('SELECT * FROM users WHERE id = $1', [userId]);
user.email; // No autocomplete, no type checking, runtime error if column doesn't exist

// Prisma - Full type safety
const user = await prisma.user.findUnique({ where: { id: userId } });
user.email; // âœ“ Autocomplete, âœ“ Type checking, âœ“ Compile-time error if wrong
```

> "Prisma provides compile-time safety for database queries. When we change the schema, TypeScript immediately shows us everywhere that needs updating. This catches bugs before they reach production. The performance overhead is negligible (~1ms per query) compared to the safety benefits."

---

## Deployment Options

### Docker Compose (Development)

**Location:** `docker/docker-compose.yml`

```bash
# Start all infrastructure
pnpm docker:up

# View logs
pnpm docker:logs

# Stop
pnpm docker:down
```

**Services included:**
- PostgreSQL (port 5432)
- Redis (port 6379)
- ClickHouse (port 8123)
- Redpanda/Kafka (port 9092)

**Best for:** Local development, testing, single-server deployments

### Kubernetes (Production)

**Location:** `k8s/`

```bash
# Deploy to Kubernetes
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/secrets/
kubectl apply -f k8s/configmaps/
kubectl apply -f k8s/databases/
kubectl apply -f k8s/deployments/
kubectl apply -f k8s/services/
kubectl apply -f k8s/ingress/
kubectl apply -f k8s/hpa/
```

**Features:**
- Horizontal Pod Autoscaler (scales proxy from 3â†’20 pods)
- Pod anti-affinity (spreads pods across nodes)
- Rolling updates with zero downtime
- Liveness/readiness probes
- Resource limits and requests
- Ingress with TLS termination

**Best for:** Production, high availability, auto-scaling

### Comparison

| Aspect | Docker Compose | Kubernetes |
|--------|---------------|------------|
| **Use Case** | Development, single host | Production, multi-host |
| **Scaling** | Manual | Automatic (HPA) |
| **High Availability** | None | Built-in |
| **Load Balancing** | Basic | Advanced (Ingress) |
| **Complexity** | Low | High |
| **Secret Management** | .env files | Kubernetes Secrets / External Secrets |

### Production Recommendations

1. **Use managed databases:**
   - AWS RDS / Google Cloud SQL for PostgreSQL
   - AWS ElastiCache / Google Memorystore for Redis
   - Confluent Cloud for Kafka
   - ClickHouse Cloud for analytics

2. **Use External Secrets Operator** with AWS Secrets Manager or HashiCorp Vault

3. **Enable monitoring** with Prometheus + Grafana

4. **Configure resource limits** based on load testing

---

## Interview Defense Guide

### Question: "Why not use a managed solution like AWS API Gateway?"

**Your Answer:**

> "AWS API Gateway is excellent for simple use cases, but RateGuard addresses gaps:
>
> 1. **Cost tracking with token-level granularity** - API Gateway doesn't know OpenAI's pricing model
> 2. **Custom rate limiting algorithms** - Token Bucket with burst handling, not just fixed quotas
> 3. **Multi-tenant budget management** - Per-workspace budgets with auto-shutoff
> 4. **Unified analytics** - Cross-API visibility in one dashboard
> 5. **No vendor lock-in** - Works with any cloud or on-premise
>
> That said, for simpler use cases, API Gateway is absolutely the right choice. RateGuard targets enterprises needing fine-grained AI API cost control."

### Question: "How does this scale to 100,000 requests per second?"

**Your Answer:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SCALING STRATEGY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Load Balancer (HAProxy/ALB)                                â”‚
â”‚         â”‚                                                    â”‚
â”‚         â”œâ”€â”€ Proxy Instance 1 â”€â”                             â”‚
â”‚         â”œâ”€â”€ Proxy Instance 2 â”€â”¼â”€â”€ Redis Cluster (sharded)   â”‚
â”‚         â”œâ”€â”€ Proxy Instance N â”€â”˜   (rate limit state)        â”‚
â”‚         â”‚                                                    â”‚
â”‚         â””â”€â”€ All connect to:                                 â”‚
â”‚             â”œâ”€â”€ PostgreSQL (read replicas for config)       â”‚
â”‚             â”œâ”€â”€ Kafka (partitioned by workspace_id)         â”‚
â”‚             â””â”€â”€ ClickHouse Cluster (sharded)                â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "The proxy is stateless - all state lives in Redis and PostgreSQL. We can add instances behind a load balancer. For Redis, we'd use Redis Cluster with sharding by workspace_id. PostgreSQL configs are cacheable (5-minute TTL). Kafka partitioning by workspace_id ensures ordering. ClickHouse natively supports distributed queries across shards."

### Question: "What happens if Redis goes down?"

**Your Answer:**

> "We implement **fail-open with degraded mode**:
>
> 1. If Redis is unreachable, we allow the request but log a warning
> 2. Rate limiting is temporarily disabled (fail-open)
> 3. Budget tracking falls back to async mode
> 4. Alerts trigger for operations team
>
> The alternative (fail-closed) would block all requests on Redis failure, which is worse for business. We prefer slight over-usage over complete outage. This matches how Stripe, Cloudflare, and other proxies handle Redis failures."

### Question: "How do you prevent race conditions in rate limiting?"

**Your Answer:**

```lua
-- This entire script runs ATOMICALLY in Redis
-- No other command can interleave

local tokens = redis.call('HGET', key, 'tokens')
if tokens >= requested then
    redis.call('HSET', key, 'tokens', tokens - requested)
    return {1, tokens - requested}  -- allowed
else
    return {0, tokens}  -- denied
end
```

> "Redis Lua scripts are atomic. The script is loaded once with `SCRIPT LOAD`, then executed with `EVALSHA`. During execution, Redis processes no other commands. This eliminates the race condition where two requests read the same token count and both decrement it. It's the same technique used by GitHub, Stripe, and Discord for their rate limiters."

### Question: "Why store API key hashes instead of encrypted keys?"

**Your Answer:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 API KEY SECURITY MODEL                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  User receives: rg_live_K7dF9xQ2mN8bV3hJ5wR1tY6uI0oP4lA2   â”‚
â”‚                                                              â”‚
â”‚  We store:                                                   â”‚
â”‚  - keyHash:  SHA256(key) = 7f83b1657ff1fc53b92dc18148...    â”‚
â”‚  - keyPrefix: rg_live_K7dF (for display only)               â”‚
â”‚                                                              â”‚
â”‚  On authentication:                                          â”‚
â”‚  1. User sends: Authorization: Bearer rg_live_K7dF...       â”‚
â”‚  2. We compute: SHA256(key)                                 â”‚
â”‚  3. We query: SELECT * FROM api_keys WHERE key_hash = ?     â”‚
â”‚  4. If match: authenticated!                                â”‚
â”‚                                                              â”‚
â”‚  If database is breached:                                   â”‚
â”‚  - Attacker has hashes, not keys                           â”‚
â”‚  - SHA256 is one-way (cannot reverse)                       â”‚
â”‚  - Keys remain secure                                        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Hashing is one-way; encryption is two-way. If we encrypted API keys, we'd need to store the decryption key somewhere. If attackers get the database AND the decryption key, they have all API keys. With hashing, even if they get everything, they can't reverse the hashes. This is the same pattern used for password storage and by Stripe, AWS, and GitHub for API keys."

### Question: "Why TypeScript instead of Go for the proxy?"

**Your Answer:**

> "Valid question - Go would be faster. Our reasons:
>
> 1. **Shared types** - Same TypeScript interfaces in proxy, dashboard, and shared packages
> 2. **Team expertise** - Faster development with familiar language
> 3. **npm ecosystem** - Undici, ioredis, kafkajs are battle-tested
> 4. **Good enough performance** - Fastify handles 30k req/s, sufficient for most use cases
>
> If we hit performance limits, we could rewrite the hot path (rate limiting) in Rust as a Node.js native addon, or extract it to a Go microservice. But premature optimization is the root of all evil - TypeScript is fast enough and significantly more productive."

### Question: "How do you ensure data consistency across databases?"

**Your Answer:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CONSISTENCY MODEL                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  STRONG CONSISTENCY (PostgreSQL):                           â”‚
â”‚  - User accounts, API configs, API keys                     â”‚
â”‚  - ACID transactions                                        â”‚
â”‚  - Source of truth                                          â”‚
â”‚                                                              â”‚
â”‚  EVENTUAL CONSISTENCY (ClickHouse):                         â”‚
â”‚  - Analytics events                                         â”‚
â”‚  - 1-5 second delay acceptable                              â”‚
â”‚  - Kafka provides durability                                â”‚
â”‚                                                              â”‚
â”‚  BEST-EFFORT (Redis):                                       â”‚
â”‚  - Rate limit state                                         â”‚
â”‚  - Budget counters                                          â”‚
â”‚  - If lost, temporarily over-serve (acceptable)             â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "We use different consistency models for different data:
>
> - **Config data** (PostgreSQL): Strong consistency - a deleted API key must immediately stop working
> - **Analytics** (ClickHouse): Eventual consistency - 5-second delay in dashboards is fine
> - **Rate limits** (Redis): Best-effort - if Redis restarts, we temporarily over-serve while state rebuilds
>
> This is the CAP theorem in practice. We can't have consistency, availability, and partition tolerance for everything. We choose the right tradeoff for each data type."
